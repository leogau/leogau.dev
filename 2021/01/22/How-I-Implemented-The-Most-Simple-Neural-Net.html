<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How I Implemented The Most Simple Neural Network Using Python | Leo Gau</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="How I Implemented The Most Simple Neural Network Using Python" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Training a neural network to output ‘42’ when given ‘5’" />
<meta property="og:description" content="Training a neural network to output ‘42’ when given ‘5’" />
<link rel="canonical" href="https://leogau.dev/2021/01/22/How-I-Implemented-The-Most-Simple-Neural-Net.html" />
<meta property="og:url" content="https://leogau.dev/2021/01/22/How-I-Implemented-The-Most-Simple-Neural-Net.html" />
<meta property="og:site_name" content="Leo Gau" />
<meta property="og:image" content="https://leogau.dev/images/SimpleNN.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-22T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://leogau.dev/2021/01/22/How-I-Implemented-The-Most-Simple-Neural-Net.html","@type":"BlogPosting","headline":"How I Implemented The Most Simple Neural Network Using Python","dateModified":"2021-01-22T00:00:00-06:00","datePublished":"2021-01-22T00:00:00-06:00","image":"https://leogau.dev/images/SimpleNN.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://leogau.dev/2021/01/22/How-I-Implemented-The-Most-Simple-Neural-Net.html"},"description":"Training a neural network to output ‘42’ when given ‘5’","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://leogau.dev/feed.xml" title="Leo Gau" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Leo Gau</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
            <a class="page-link" href="https://twitter.com/leogau" target="_blank">About</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How I Implemented The Most Simple Neural Network Using Python</h1><p class="page-description">Training a neural network to output '42' when given '5'</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-22T00:00:00-06:00" itemprop="datePublished">
        Jan 22, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Grokking Deep Learning">Grokking Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Deep Learning">Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/leogau/leogau.dev/tree/master/_notebooks/2021-01-22-How-I-Implemented-The-Most-Simple-Neural-Net.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/leogau/leogau.dev/master?filepath=_notebooks%2F2021-01-22-How-I-Implemented-The-Most-Simple-Neural-Net.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/leogau/leogau.dev/blob/master/_notebooks/2021-01-22-How-I-Implemented-The-Most-Simple-Neural-Net.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Context">Context </a></li>
<li class="toc-entry toc-h1"><a href="#What-I'm-Building">What I&#39;m Building </a></li>
<li class="toc-entry toc-h1"><a href="#The-Code">The Code </a></li>
<li class="toc-entry toc-h1"><a href="#Neural-Networks">Neural Networks </a>
<ul>
<li class="toc-entry toc-h3"><a href="#The-2-Things-A-Neural-Network-Needs-To-Make-A-Prediction">The 2 Things A Neural Network Needs To Make A Prediction </a>
<ul>
<li class="toc-entry toc-h4"><a href="#The-Weight">The Weight </a></li>
<li class="toc-entry toc-h4"><a href="#The-Input">The Input </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#So-how-does-this-thing-learn?">So how does this thing learn? </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-The-Prediction">1. The Prediction </a></li>
<li class="toc-entry toc-h2"><a href="#2.-How-much-are-we-off-by?">2. How much are we off by? </a></li>
<li class="toc-entry toc-h2"><a href="#3.-Adjusting-the-weights">3. Adjusting the weights </a></li>
<li class="toc-entry toc-h2"><a href="#4.-Training-rounds">4. Training rounds </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#So-what-did-I-accomplish?">So what did I accomplish? </a></li>
<li class="toc-entry toc-h1"><a href="#What's-next?">What&#39;s next? </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-01-22-How-I-Implemented-The-Most-Simple-Neural-Net.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Context">
<a class="anchor" href="#Context" aria-hidden="true"><span class="octicon octicon-link"></span></a>Context<a class="anchor-link" href="#Context"> </a>
</h1>
<p>I've been reading the book <a href="https://www.manning.com/books/grokking-deep-learning">Grokking Deep Learning</a> by <a href="https://twitter.com/iamtrask">Andrew W. Trask</a> and instead of summarizing concepts, I want to review them by building a simple neural network. This neural network will use the concepts in the first 4 chapters of the book.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="What-I'm-Building">
<a class="anchor" href="#What-I'm-Building" aria-hidden="true"><span class="octicon octicon-link"></span></a>What I'm Building<a class="anchor-link" href="#What-I'm-Building"> </a>
</h1>
<p>I'm going to build a neural network which outputs a target number given a specific input number. For example, given the number <code>5</code>, I want the neural network to output the number <code>42</code>.</p>
<p>Now I can hear you think to yourself, "That's stupid. How is that better than a function with the line <code>return 42</code> in the body?"</p>
<p>What's cool about this code is that I didn't type the number <code>5</code> or <code>42</code> anywhere in the body of the network. Instead, I told the network I wanted it to print <code>42</code> when it recieved <code>5</code> as an input and it figure out how to adjust itself to do that.</p>
<p>In fact, I could train the network on any 2 numbers using the same code. Try changing the parameters yourself and test it out!</p>
<p>With that context, let's see what the code looks like for this most simple neural network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-Code">
<a class="anchor" href="#The-Code" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Code<a class="anchor-link" href="#The-Code"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SimpleNN</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
        
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">goal</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">goal</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="n">derivative</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="nb">input</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">derivative</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Error: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">neural_network</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="c1"># Train the SimpleNN </span>
<span class="n">neural_network</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">goal</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Error: 1369.0
Error: 770.0625
Error: 433.16015625
Error: 243.6525878906251
Error: 137.05458068847665
Error: 77.09320163726807
Error: 43.36492592096329
Error: 24.39277083054185
Error: 13.72093359217979
Error: 7.718025145601132
Error: 4.341389144400637
Error: 2.442031393725358
Error: 1.373642658970514
Error: 0.7726739956709141
Error: 0.43462912256489855
Error: 0.24447888144275018
Error: 0.13751937081154697
Error: 0.07735464608149517
Error: 0.043511988420844
Error: 0.02447549348672308
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">neural_network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>41.88266515825944</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After 20 rounds of training, the network's final prediction is off by about <code>0.02</code>. Not bad!</p>
<p>Even in this barebones neural network, there's a lot going on. Let's take it line by line.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Neural-Networks">
<a class="anchor" href="#Neural-Networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Networks<a class="anchor-link" href="#Neural-Networks"> </a>
</h1>
<p>A neural network is a collection of weights being used to compute an error function. That's it.</p>
<p>The interesting thing about this statement is that for any error function, no matter how complicated, you can compute the relationship between a weight and the final error of the network. Therefore, after each prediction, we can change each weight in the network to inch the final error towards 0.</p>
<p>Let's take a look what a neural network needs to make a prediction.</p>
<h3 id="The-2-Things-A-Neural-Network-Needs-To-Make-A-Prediction">
<a class="anchor" href="#The-2-Things-A-Neural-Network-Needs-To-Make-A-Prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>The 2 Things A Neural Network Needs To Make A Prediction<a class="anchor-link" href="#The-2-Things-A-Neural-Network-Needs-To-Make-A-Prediction"> </a>
</h3>
<h4 id="The-Weight">
<a class="anchor" href="#The-Weight" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Weight<a class="anchor-link" href="#The-Weight"> </a>
</h4>
<div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="mf">1.0</span>
</pre></div>
<p>I mentioned before that a neural network is just "a collection of weights". So what are weights?</p>
<p><code>weight</code> is a number that the neural network stores and remembers. It can be thought of of the <em>"memory"</em> of the network. After each round of training, the network updates the <code>weight</code> to make more accurate predictions.</p>
<p>In our network, I set <code>weight=1.0</code>. I just used trial-and-error to figure out a good starting weight for this problem.</p>
<h4 id="The-Input">
<a class="anchor" href="#The-Input" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Input<a class="anchor-link" href="#The-Input"> </a>
</h4>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">goal</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
</pre></div>
<p><code>input</code> is a number that the neural network accepts. This can be thought of as information from the outside world.</p>
<p>In our network, I set <code>input=5</code> when I start training the network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="So-how-does-this-thing-learn?">
<a class="anchor" href="#So-how-does-this-thing-learn?" aria-hidden="true"><span class="octicon octicon-link"></span></a>So how does this thing learn?<a class="anchor-link" href="#So-how-does-this-thing-learn?"> </a>
</h1>
<p>I use a method called <strong>Stochasitc Gradient Descent</strong> to get <code>SimpleNN</code> to learn the training data.</p>
<p>At a high level, the 4 step process is:</p>
<ol>
<li>Make a prediction using a given input</li>
<li>Calculate the error</li>
<li>Calculate the derivative to tell us how much to adjust the weights by</li>
<li>Adjust the weight and go back to step 1.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-The-Prediction">
<a class="anchor" href="#1.-The-Prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. The Prediction<a class="anchor-link" href="#1.-The-Prediction"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
</pre></div>
<p>When the neural network has both an <code>input</code> and <code>weight</code>, it multiplies them together to make a prediction. Every single neural network, from the most simple to ones with 1000s of layers works this way.</p>
<h2 id="2.-How-much-are-we-off-by?">
<a class="anchor" href="#2.-How-much-are-we-off-by?" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. How much are we off by?<a class="anchor-link" href="#2.-How-much-are-we-off-by?"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="n">delta</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">goal</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">**</span> <span class="mi">2</span>
</pre></div>
<p>So we've seen that the network make a prediction by multiplying <code>input</code> and <code>weight</code>. After it makes a prediction, the network is able to calculate how much it was off by.</p>
<p>A neural network learning is all about error attribution. How much did each weight contribute to the overall error of the system and how can we change the weight so that error is minimized? In our example, it's easy to figure out since there is only 1 weight.</p>
<p>How do we calculate the error? One thing we need to keep in mind is that we want the error to be a positive number. If the error is allowed to be negative, multiple errors might accidentally cancel each other out when averaged together.</p>
<p>In our case, we square the amount we are off by. Why square instead of something straightforward like absolute value? Squaring gives us a sense of importance. Large errors are magnified while small errors are minimized. Therefore, we can prioritize large errors before small errors. Absolute value doesn't give us this additional sense of importance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Adjusting-the-weights">
<a class="anchor" href="#3.-Adjusting-the-weights" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Adjusting the weights<a class="anchor-link" href="#3.-Adjusting-the-weights"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="n">derivative</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="nb">input</span>
<span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">derivative</span><span class="p">)</span>
</pre></div>
<p>The network figures out how much to adjust the weights by using a derivative. How does derivative play into this process? What a derivative tells us is the direction and amount one variable changes when you change a different variable. In our case, derivatives tell us much much error changes when you change the weight. Given that we want error to be 0, this is exactly what we need.</p>
<p>The network calculates the derivative by multiplying the <code>delta</code> by the weight's input to get the <code>weight_delta</code>. <code>weight_delta</code> is the direction and the amount we're going to change the weight by.</p>
<div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
</pre></div>
<p>One bit of nuance is the variable <code>alpha</code>. <code>alpha</code> is a throttle limiting how much we actually adjust the weights by. Determining the appropriate rate of change for the weights of a neural network is a challenge. If the steps are too large, the network will overshoot the error getting to zero and start acting in unpredictable ways. If the steps are too small, the network will take a long time and need a very large number of training cycles.</p>
<p>The solution to this problem is to multiply partial derivative by a single number between 0 and 1. This lets us control the rate of change and adjust the learning as needed.</p>
<p>Finding the appropriate <code>alpha</code> is often done through trial and error so we're just going to hard code is here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Training-rounds">
<a class="anchor" href="#4.-Training-rounds" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Training rounds<a class="anchor-link" href="#4.-Training-rounds"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="n">neural_network</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">goal</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</pre></div>
<p>Finally, there's the concept of <code>epochs</code>. This refers to the number of times the network will go through the entire data set. The appropriate number of epochs for a problem will often be found through trial and error.</p>
<p>I'm using <code>20</code> in the example, which I found by running the training with different epochs and picking the lowest one with an acceptable error. Feel free to experiment with the number of epochs and see what happens at different numbers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="So-what-did-I-accomplish?">
<a class="anchor" href="#So-what-did-I-accomplish?" aria-hidden="true"><span class="octicon octicon-link"></span></a>So what did I accomplish?<a class="anchor-link" href="#So-what-did-I-accomplish?"> </a>
</h1>
<p>I'm able to give the neural network the number <code>5</code>, and have it output a number very close to our goal number <code>42</code> without putting the number <code>5</code> or <code>42</code> in the body of the function.</p>
<p>I also learned the basic parts which make up all neural networks and we learned the process of how the network learns.</p>
<p>As we start to move into networks with multiple inputs, multiple outputs, and multiple layers, it's going to get a lot more complicated. However, the mental model stays the same. The network makes a prediction by multiplying the recieved input with its stored weights. It measures the error, takes the derivative, and adjusts the weights so that error moves towards 0. Then it goes again.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="What's-next?">
<a class="anchor" href="#What's-next?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What's next?<a class="anchor-link" href="#What's-next?"> </a>
</h1>
<p>I'm going to tackle multiple inputs and multiple outputs. I'll see how matricies come into play and how we can build a simple library to do matrix math.</p>
<p>See you then!</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="leogau/leogau.dev"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/2021/01/22/How-I-Implemented-The-Most-Simple-Neural-Net.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Exploring Deep Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/leogau" title="leogau"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/leogau" title="leogau"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
